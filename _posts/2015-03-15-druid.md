---
layout: post
title: "Druid: A Real-time Analytical Data Store"
date: 2015-03-15
comments: True
categories: "big-data"
description: "Druid is an open source data store designed for real-time exploratory analytics on large data sets. The system combines a column-oriented storage layout, a distributed, shared-nothing architecture, and an advanced indexing structure to allow for the arbitrary exploration of billion-row tables with sub-second latencies."
---

Druid is an open source data store designed for real-time exploratory analytics on large data sets. The system combines a column-oriented storage layout, a distributed, shared-nothing architecture, and an advanced indexing structure to allow for the arbitrary exploration of billion-row tables with sub-second latencies.

<!--more-->

<hr class="soft"/>

### Problem and motivation

* The goal is to provide a multi-tenant, __highly available__ system which serves the functionality of __low latency data ingestion and interactive query platform__. [main novelty]

### Design Decision

* __Low latency__
  * Specialize node servers to process real-time information with Message bus for parallelism  
* __High Availability__
  * Make node servers query-able when external failure happened

### Overall Architecture
  ![alt text](/images/posts/2015-03-15-druid-1.png)

### System Architecture

* Real-time node
  * Only concerned with events for __some small time range__
  * Persists real-time query data in memory and on disk
  * Periodically hand off immutable batches of events to “Deep Storage” (such as HDFS, S3)

* Message Bus such as Kafka

  ![alt text](/images/posts/2015-03-15-druid-2.png)

  * Collaborated with real-time node and serve as a producer for event stream.
  * Functionality
    1. Acts as a __buffer__ => fast recover for real-time node
    2. Acts as a __single end-point__ => enables data partition and data replication

* Historical node
  * Functions to __only load, drop, serve__ immutable data blocks created by real-time nodes
  * Shared-nothing architecture, connect Zookeeper for segment info, cache for fast recovery
  * Features
    * Supports __read consistency__
    * Available when Zookeeper down(only serve what it have)
    * Grouped into different “Tiers” [with different importance]

* Broker node
  * Functionality
    * Act as a query router, to route query request to real-time node or historical node, merge partial result before return to client
    * __cache__ results for no re-computation at historical node, never cache real-time result
  * Keeps query-able when Zookeeper down, use last knowledge of clusters to route

* Coordinator node
  * Functionality
    * In charge of data management and distribution on historical node
  * Use __multi-version concurrency__ control swapping protocol to manage immutable segments
  * Connect to MySQL to maintain segments distribution info
  * Functions as a load balancer , segments replication manager for historical node.
  * Unable to work when Zookeeper down, but not affect data availability

### Storage format

* Data tables in Druid are collections of __timestamped(required)__ events and partitioned into a set of segments
* Stored in a column orientation for __CPU efficiency__, associate with different compression methods

### References

[**[1]**](http://static.druid.io/docs/druid.pdf)Druid: A Real-time Analytical Data Store
